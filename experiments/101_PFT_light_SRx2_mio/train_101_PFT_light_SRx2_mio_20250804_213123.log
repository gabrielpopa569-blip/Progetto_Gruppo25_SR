2025-08-04 21:31:23,600 INFO: 
                ____                _       _____  ____
               / __ ) ____ _ _____ (_)_____/ ___/ / __ \
              / __  |/ __ `// ___// // ___/\__ \ / /_/ /
             / /_/ // /_/ /(__  )/ // /__ ___/ // _, _/
            /_____/ \__,_//____//_/ \___//____//_/ |_|
     ______                   __   __                 __      __
    / ____/____   ____   ____/ /  / /   __  __ _____ / /__   / /
   / / __ / __ \ / __ \ / __  /  / /   / / / // ___// //_/  / /
  / /_/ // /_/ // /_/ // /_/ /  / /___/ /_/ // /__ / /<    /_/
  \____/ \____/ \____/ \____/  /_____/\____/ \___//_/|_|  (_)
    
Version Information: 
	BasicSR: 0.1.1
	PyTorch: 2.7.1+cu126
	TorchVision: 0.22.1+cu126
2025-08-04 21:31:23,600 INFO: 
  name: 101_PFT_light_SRx2_mio
  model_type: PFTModel
  scale: 2
  num_gpu: 1
  manual_seed: 0
  find_unused_parameters: True
  datasets:[
    train:[
      name: Set5Training
      type: PairedImageDataset
      dataroot_gt: datasets/TestDataSR/HR/Set5/x2
      dataroot_lq: datasets/TestDataSR/LR/LRBI/Set5/x2
      filename_tmpl: {}x2
      io_backend:[
        type: disk
      ]
      gt_size: 128
      use_hflip: True
      use_rot: True
      num_worker_per_gpu: 5
      batch_size_per_gpu: 5
      dataset_enlarge_ratio: 1
      prefetch_mode: cuda
      pin_memory: True
      persistent_workers: True
      phase: train
      scale: 2
    ]
    val_1:[
      name: Set5Testing
      type: PairedImageDataset
      dataroot_gt: datasets/TestDataSR1/HR/Set5/x2
      dataroot_lq: datasets/TestDataSR1/LR/LRBI/Set5/x2
      io_backend:[
        type: disk
      ]
      phase: val
      scale: 2
    ]
  ]
  network_g:[
    type: PFT
    upscale: 2
    in_chans: 3
    img_size: 64
    embed_dim: 52
    depths: [2, 4, 6, 6, 6]
    num_heads: 4
    num_topk: [1024, 1024, 256, 256, 256, 256, 128, 128, 128, 128, 128, 128, 64, 64, 64, 64, 64, 64, 32, 32, 32, 32, 32, 32]
    window_size: 32
    convffn_kernel_size: 7
    img_range: 1.0
    mlp_ratio: 1
    upsampler: pixelshuffledirect
    resi_connection: 1conv
    use_checkpoint: False
  ]
  path:[
    pretrain_network_g: None
    strict_load_g: True
    resume_state: None
    experiments_root: /app/PFT-SR/experiments/101_PFT_light_SRx2_mio
    models: /app/PFT-SR/experiments/101_PFT_light_SRx2_mio/models
    training_states: /app/PFT-SR/experiments/101_PFT_light_SRx2_mio/training_states
    log: /app/PFT-SR/experiments/101_PFT_light_SRx2_mio
    visualization: /app/PFT-SR/experiments/101_PFT_light_SRx2_mio/visualization
  ]
  train:[
    ema_decay: 0.999
    optim_g:[
      type: AdamW
      lr: 0.0005
      weight_decay: 0
      betas: [0.9, 0.99]
    ]
    scheduler:[
      type: MultiStepLR
      milestones: [250000, 400000, 450000, 475000, 490000]
      gamma: 0.5
    ]
    total_iter: 1000
    warmup_iter: 1
    pixel_opt:[
      type: L1Loss
      loss_weight: 1.0
      reduction: mean
    ]
  ]
  val:[
    val_freq: 10000.0
    save_img: False
    metrics:[
      psnr:[
        type: calculate_psnr
        crop_border: 2
        test_y_channel: True
      ]
      ssim:[
        type: calculate_ssim
        crop_border: 2
        test_y_channel: True
      ]
    ]
  ]
  logger:[
    print_freq: 10
    save_checkpoint_freq: 10
    use_tb_logger: True
    wandb:[
      project: None
      resume_id: None
    ]
  ]
  dist_params:[
    backend: nccl
    port: 29500
  ]
  dist: False
  rank: 0
  world_size: 1
  auto_resume: False
  is_train: True
  root_path: /app/PFT-SR

2025-08-04 21:31:23,652 INFO: Dataset [PairedImageDataset] - Set5Training is built.
2025-08-04 21:31:23,652 INFO: Training statistics:
	Number of train images: 5
	Dataset enlarge ratio: 1
	Batch size per gpu: 5
	World size (gpu number): 1
	Require iter number per epoch: 1
	Total epochs: 1000; iters: 1000.
2025-08-04 21:31:23,653 INFO: Dataset [PairedImageDataset] - Set5Testing is built.
2025-08-04 21:31:23,653 INFO: Number of val images/folders in Set5Testing: 5
2025-08-04 21:31:23,715 INFO: Network [PFT] is created.
2025-08-04 21:31:23,864 INFO: Network: PFT, with parameters: 775,532
2025-08-04 21:31:23,864 INFO: PFT(
  (conv_first): Conv2d(3, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (patch_embed): PatchEmbed(
    (norm): LayerNorm((52,), eps=1e-05, elementwise_affine=True)
  )
  (patch_unembed): PatchUnEmbed()
  (layers): ModuleList(
    (0): PFTB(
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
      (residual_group): BasicBlock(
        dim=52, input_resolution=(64, 64), depth=2
        (layers): ModuleList(
          (0-1): 2 x PFTransformerLayer(
            (softmax): Softmax(dim=-1)
            (lrelu): LeakyReLU(negative_slope=0.01)
            (sigmoid): Sigmoid()
            (norm1): LayerNorm((52,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((52,), eps=1e-05, elementwise_affine=True)
            (wqkv): Linear(in_features=52, out_features=156, bias=True)
            (v_LePE): dwconv(
              (depthwise_conv): Sequential(
                (0): Conv2d(52, 52, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=52)
                (1): GELU(approximate='none')
              )
            )
            (attn_win): WindowAttention(
              dim=52, window_size=(32, 32), num_heads=4, qkv_bias=True
              (proj): Linear(in_features=52, out_features=52, bias=True)
              (softmax): Softmax(dim=-1)
            )
            (convffn): ConvFFN(
              (fc1): Linear(in_features=52, out_features=52, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(52, 52, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=52)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=52, out_features=52, bias=True)
            )
          )
        )
      )
      (conv): Conv2d(52, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (1): PFTB(
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
      (residual_group): BasicBlock(
        dim=52, input_resolution=(64, 64), depth=4
        (layers): ModuleList(
          (0-3): 4 x PFTransformerLayer(
            (softmax): Softmax(dim=-1)
            (lrelu): LeakyReLU(negative_slope=0.01)
            (sigmoid): Sigmoid()
            (norm1): LayerNorm((52,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((52,), eps=1e-05, elementwise_affine=True)
            (wqkv): Linear(in_features=52, out_features=156, bias=True)
            (v_LePE): dwconv(
              (depthwise_conv): Sequential(
                (0): Conv2d(52, 52, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=52)
                (1): GELU(approximate='none')
              )
            )
            (attn_win): WindowAttention(
              dim=52, window_size=(32, 32), num_heads=4, qkv_bias=True
              (proj): Linear(in_features=52, out_features=52, bias=True)
              (softmax): Softmax(dim=-1)
            )
            (convffn): ConvFFN(
              (fc1): Linear(in_features=52, out_features=52, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(52, 52, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=52)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=52, out_features=52, bias=True)
            )
          )
        )
      )
      (conv): Conv2d(52, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (2-4): 3 x PFTB(
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
      (residual_group): BasicBlock(
        dim=52, input_resolution=(64, 64), depth=6
        (layers): ModuleList(
          (0-5): 6 x PFTransformerLayer(
            (softmax): Softmax(dim=-1)
            (lrelu): LeakyReLU(negative_slope=0.01)
            (sigmoid): Sigmoid()
            (norm1): LayerNorm((52,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((52,), eps=1e-05, elementwise_affine=True)
            (wqkv): Linear(in_features=52, out_features=156, bias=True)
            (v_LePE): dwconv(
              (depthwise_conv): Sequential(
                (0): Conv2d(52, 52, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=52)
                (1): GELU(approximate='none')
              )
            )
            (attn_win): WindowAttention(
              dim=52, window_size=(32, 32), num_heads=4, qkv_bias=True
              (proj): Linear(in_features=52, out_features=52, bias=True)
              (softmax): Softmax(dim=-1)
            )
            (convffn): ConvFFN(
              (fc1): Linear(in_features=52, out_features=52, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(52, 52, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=52)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=52, out_features=52, bias=True)
            )
          )
        )
      )
      (conv): Conv2d(52, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (norm): LayerNorm((52,), eps=1e-05, elementwise_affine=True)
  (conv_after_body): Conv2d(52, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsample): UpsampleOneStep(
    (0): Conv2d(52, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=2)
  )
)
2025-08-04 21:31:23,866 INFO: Use Exponential Moving Average with decay: 0.999
2025-08-04 21:31:23,921 INFO: Network [PFT] is created.
2025-08-04 21:31:23,970 INFO: Loss [L1Loss] is created.
2025-08-04 21:31:23,973 INFO: Model [PFTModel] is created.
2025-08-04 21:31:24,100 INFO: Use cuda prefetch dataloader
2025-08-04 21:31:24,100 INFO: Start training from epoch: 0, iter: 0
2025-08-04 21:31:29,580 INFO: [101_P..][epoch:  9, iter:      10, lr:(5.000e-04,)] [eta: 0:05:59, time (data): 0.548 (0.057)] l_pix: 1.1118e-01 
2025-08-04 21:31:29,581 INFO: Saving models and training states.
2025-08-04 21:31:34,317 INFO: [101_P..][epoch: 19, iter:      20, lr:(5.000e-04,)] [eta: 0:06:47, time (data): 0.501 (0.060)] l_pix: 7.5742e-02 
2025-08-04 21:31:34,318 INFO: Saving models and training states.
2025-08-04 21:31:39,156 INFO: [101_P..][epoch: 29, iter:      30, lr:(5.000e-04,)] [eta: 0:07:04, time (data): 0.484 (0.060)] l_pix: 6.3003e-02 
2025-08-04 21:31:39,156 INFO: Saving models and training states.
2025-08-04 21:31:43,785 INFO: [101_P..][epoch: 39, iter:      40, lr:(5.000e-04,)] [eta: 0:07:05, time (data): 0.474 (0.060)] l_pix: 5.1231e-02 
2025-08-04 21:31:43,785 INFO: Saving models and training states.
2025-08-04 21:31:48,459 INFO: [101_P..][epoch: 49, iter:      50, lr:(5.000e-04,)] [eta: 0:07:05, time (data): 0.469 (0.061)] l_pix: 4.4142e-02 
2025-08-04 21:31:48,460 INFO: Saving models and training states.
2025-08-04 21:31:53,130 INFO: [101_P..][epoch: 59, iter:      60, lr:(5.000e-04,)] [eta: 0:07:04, time (data): 0.466 (0.061)] l_pix: 5.0833e-02 
2025-08-04 21:31:53,130 INFO: Saving models and training states.
2025-08-04 21:31:57,827 INFO: [101_P..][epoch: 69, iter:      70, lr:(5.000e-04,)] [eta: 0:07:01, time (data): 0.463 (0.062)] l_pix: 7.1760e-02 
2025-08-04 21:31:57,828 INFO: Saving models and training states.
2025-08-04 21:32:02,520 INFO: [101_P..][epoch: 79, iter:      80, lr:(5.000e-04,)] [eta: 0:06:59, time (data): 0.462 (0.062)] l_pix: 5.0175e-02 
2025-08-04 21:32:02,521 INFO: Saving models and training states.
2025-08-04 21:32:07,134 INFO: [101_P..][epoch: 89, iter:      90, lr:(5.000e-04,)] [eta: 0:06:55, time (data): 0.460 (0.063)] l_pix: 4.1248e-02 
2025-08-04 21:32:07,135 INFO: Saving models and training states.
2025-08-04 21:32:11,822 INFO: [101_P..][epoch: 99, iter:     100, lr:(5.000e-04,)] [eta: 0:06:51, time (data): 0.459 (0.063)] l_pix: 3.9044e-02 
2025-08-04 21:32:11,823 INFO: Saving models and training states.
